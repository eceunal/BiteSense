{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAiyY2rTwwH7"
      },
      "outputs": [],
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps --upgrade timm"
      ],
      "metadata": {
        "id": "QEukSORDw9yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU evaluate"
      ],
      "metadata": {
        "id": "XKNQyYx6xJmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "import random\n",
        "from unsloth import FastVisionModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "26EfQ2r6xOJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "cWU-UPMI5zGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bugs = load_dataset(\"eceunal/bug-bite-images-aug_v3\", split=\"train+validation\")\n",
        "img, label = bugs[0][\"image\"], bugs.features[\"label\"].int2str(bugs[0][\"label\"])\n",
        "print(label)"
      ],
      "metadata": {
        "id": "peq2eIjPxT4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Which insect bite is this if there is a bite?\"\n",
        "\n",
        "int2str = bugs.features[\"label\"].int2str\n",
        "\n",
        "def convert_to_conversation(sample):\n",
        "    conversation = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\",  \"text\": instruction},\n",
        "                {\"type\": \"image\", \"image\": sample[\"image\"]},\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": int2str(sample[\"label\"])}],\n",
        "        },\n",
        "    ]\n",
        "    return {\"messages\": conversation}\n",
        "\n",
        "converted_dataset = [convert_to_conversation(sample) for sample in bugs]"
      ],
      "metadata": {
        "id": "Xt5p1DH2xVxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(\n",
        "        converted_dataset,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        shuffle=True\n",
        ")\n",
        "\n",
        "print(len(train), len(test))"
      ],
      "metadata": {
        "id": "AMKby5dWxXtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Base Model"
      ],
      "metadata": {
        "id": "jBuH3T2d52gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, processor = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/gemma-3n-E2B-it\",\n",
        "    load_in_4bit = True,\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        ")"
      ],
      "metadata": {
        "id": "VgqzzlZpxaHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune"
      ],
      "metadata": {
        "id": "F3DgSf6-56T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "     model,\n",
        "     finetune_vision_layers     = True,\n",
        "     finetune_language_layers   = True,\n",
        "     finetune_attention_modules = True,\n",
        "     finetune_mlp_modules       = True,\n",
        "\n",
        "     r = 16,\n",
        "     lora_alpha = 16,\n",
        "     lora_dropout = 0.05,\n",
        "     bias = \"none\",\n",
        "     random_state = 3407,\n",
        "     target_modules = \"all-linear\",\n",
        "     modules_to_save = [\n",
        "         \"lm_head\",\n",
        "         \"embed_tokens\",\n",
        "     ],\n",
        " )"
      ],
      "metadata": {
        "id": "m3-RVvHkxiWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "FastVisionModel.for_training(model)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset = train,\n",
        "    processing_class = processor.tokenizer,\n",
        "    data_collator=UnslothVisionDataCollator(model, processor, resize=512),\n",
        "    max_seq_length = 2048,\n",
        "    args = SFTConfig(\n",
        "        num_train_epochs = 2,\n",
        "        per_device_train_batch_size = 1,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        gradient_checkpointing = False,\n",
        "        max_grad_norm = 0.3,\n",
        "        warmup_steps = 5,\n",
        "        learning_rate = 2e-4,\n",
        "        logging_steps = 1,\n",
        "        save_strategy=\"steps\",\n",
        "        optim = \"adamw_torch_fused\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",\n",
        "        save_steps = 200,\n",
        "        # MUST for vision finetuning:\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "    )\n",
        ")\n",
        "\n",
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "TMIoK5I3xrUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats"
      ],
      "metadata": {
        "id": "z9n4SaFB26Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = trainer.state.log_history\n",
        "\n",
        "loss_values = [entry[\"loss\"] for entry in logs if \"loss\" in entry]\n",
        "steps = [entry[\"step\"] for entry in logs if \"loss\" in entry]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(steps, loss_values, marker='o')\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.xlabel(\"Training Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hLkhv2wn6L3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "jg-i1Noc6Acp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict"
      ],
      "metadata": {
        "id": "P8QAJ48c29fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bugs = load_dataset(\"eceunal/bug-bite-images-aug_v3\", split=\"train+validation\")\n",
        "img, label = bugs[0][\"image\"], bugs.features[\"label\"].int2str(bugs[0][\"label\"])\n",
        "print(label)"
      ],
      "metadata": {
        "id": "8nT37pUz31OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "af2HUhnb36Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            { \"type\": \"image\", \"image\": img},\n",
        "            { \"type\": \"text\", \"text\": instruction }\n",
        "        ]\n",
        "    }]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=250)\n",
        "\n",
        "print(processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n",
        "\n",
        "prompt_len = inputs[\"input_ids\"].shape[-1]\n",
        "answer_ids = outputs[0, prompt_len:]\n",
        "answer_text = processor.tokenizer.decode(\n",
        "    answer_ids, skip_special_tokens=True\n",
        ").strip()\n",
        "\n",
        "print(answer_text)"
      ],
      "metadata": {
        "id": "bI7D_YGA4Ssm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tCPDjNTu7jOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "Gjt1rtD_7n7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push Merged Model to HF"
      ],
      "metadata": {
        "id": "U7fZbXGT9nAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub_merged(\"eceunal/insectra-fine-tuned\", processor, token = hf_token)"
      ],
      "metadata": {
        "id": "pXwXr7dq7YvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push Trainer to HF"
      ],
      "metadata": {
        "id": "4QHuAC_L9rBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('gemma-fine-tuned')"
      ],
      "metadata": {
        "id": "nZGa1HPz9qhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub('gemma-fine-tuned')"
      ],
      "metadata": {
        "id": "gwVJTVYd-DJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"Write me a story\"\n",
        "\n",
        "messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            { \"type\": \"text\", \"text\": instruction }\n",
        "        ]\n",
        "    }]\n",
        "\n",
        "inputs = processor.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(model.device)\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=250)\n",
        "\n",
        "print(processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n",
        "\n",
        "prompt_len = inputs[\"input_ids\"].shape[-1]\n",
        "answer_ids = outputs[0, prompt_len:]\n",
        "answer_text = processor.tokenizer.decode(\n",
        "    answer_ids, skip_special_tokens=True\n",
        ").strip()\n",
        "\n",
        "print(answer_text)"
      ],
      "metadata": {
        "id": "vr1rpgyxKRY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "SLie1FfHPHLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import TextStreamer\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "\n",
        "pred_rows = []\n",
        "\n",
        "for idx, sample in tqdm(enumerate(test), total=len(test)):\n",
        "    pil_img = next(c for c in sample[\"messages\"][0][\"content\"]\n",
        "                   if c[\"type\"]==\"image\")[\"image\"]\n",
        "    if isinstance(pil_img, dict):\n",
        "        pil_img = Image.open(pil_img[\"path\"])\n",
        "    elif isinstance(pil_img, str):\n",
        "        pil_img = Image.open(pil_img)\n",
        "    if pil_img.mode == \"L\":\n",
        "        pil_img = pil_img.convert(\"RGB\")\n",
        "\n",
        "    instruction = \"Which insect bite is this if there is a bite? Return only bite name or no bite, no additional comment needed\"\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": pil_img},\n",
        "                {\"type\": \"text\", \"text\": instruction}\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    inputs = processor.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      tokenize=True,\n",
        "      return_dict=True,\n",
        "      return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens=512)\n",
        "    print(processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n",
        "    prompt_len = inputs[\"input_ids\"].shape[-1]\n",
        "    answer_ids = outputs[0, prompt_len:]  # remove prompt tokens\n",
        "    answer_text = processor.tokenizer.decode(\n",
        "              answer_ids, skip_special_tokens=True\n",
        "    ).strip()\n",
        "\n",
        "    print(\"Prediction: \" + answer_text + \".   Real Answer: \" + sample[\"messages\"][1][\"content\"][0][\"text\"])\n",
        "    pred_rows.append({\n",
        "        \"row_idx\":        idx,\n",
        "        \"gold_label\":     sample[\"messages\"][1][\"content\"][0][\"text\"],\n",
        "        \"raw_prediction\": answer_text,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(pred_rows)\n",
        "df.to_csv(\"predictions.csv\", index=False)\n",
        "print(f\"✅  Saved {len(df)} rows to predictions.csv\")"
      ],
      "metadata": {
        "id": "Xc46Xvh8KThQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation for Fine-Tuned Gemma 3n"
      ],
      "metadata": {
        "id": "2kU64svYZ8NR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "df = pd.read_csv(\"predictions.csv\")    # columns: prediction, real_answer\n",
        "\n",
        "\n",
        "# ----- 2  normalise → list-of-tokens ---------------------------------------\n",
        "def normalise_tokens(txt: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    ‣ lower-cases\n",
        "    ‣ strips non-alphanumerics\n",
        "    ‣ splits on whitespace      → returns a list of “clean” tokens\n",
        "    \"\"\"\n",
        "    if pd.isna(txt):\n",
        "        return []\n",
        "    cleaned = re.sub(r\"[^0-9a-zA-Z ]\", \" \", txt).lower()\n",
        "    tokens  = cleaned.split()\n",
        "    return tokens\n",
        "\n",
        "df[\"tok_pred\"] = df[\"raw_prediction\"].apply(normalise_tokens)\n",
        "df[\"tok_real\"] = df[\"gold_label\"].apply(normalise_tokens)\n",
        "\n",
        "\n",
        "# ----- 3  rule: real-tokens ⊆ pred-tokens  OR  pred-tokens ⊆ real-tokens ----\n",
        "def subset_or_superset(row) -> bool:\n",
        "    a, b = set(row.tok_pred), set(row.tok_real)\n",
        "    return a.issuperset(b) or b.issuperset(a)\n",
        "    #       ↑ ignores any *extra* words on either side\n",
        "\n",
        "df[\"result\"] = df.apply(subset_or_superset, axis=1).map({True: \"pass\",\n",
        "                                                         False: \"fail\"})\n",
        "\n",
        "\n",
        "# ----- 4  quick report ------------------------------------------------------\n",
        "print(Counter(df[\"result\"]))            # e.g. Counter({'pass': 87, 'fail': 13})\n",
        "df.to_csv(\"pred_vs_real_with_result.csv\", index=False)\n",
        "\n",
        "display(df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bZjzGraVZ2z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"pred_vs_real_with_result.csv\")"
      ],
      "metadata": {
        "id": "FwLJEYPcGqY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (df[\"result\"] == \"pass\").mean() * 100\n",
        "\n",
        "result_counts = df[\"result\"].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar([\"Accuracy\"], [accuracy], color=\"skyblue\")\n",
        "plt.ylim(0, 100)\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(result_counts.index, result_counts.values, color=[\"green\", \"red\"])\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Pass vs Fail\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MjSpIsxKavP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "-_K8ZTAdazmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_results = df.groupby(['gold_label', 'result']).size().unstack(fill_value=0)\n",
        "\n",
        "# Plot side-by-side bars for True and False per class\n",
        "class_results.plot(kind='bar', figsize=(10,5))\n",
        "plt.xlabel(\"Gold Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"True vs False Predictions per Class\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title=\"Result\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_JwweINLGlzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation by Gemini for raw Gemma 3n Answers"
      ],
      "metadata": {
        "id": "U0Sv1gDbYXcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastVisionModel\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "BASE_ID   = \"unsloth/gemma-3n-E2B-it\"\n",
        "\n",
        "raw_model, raw_processor = FastVisionModel.from_pretrained(\n",
        "    BASE_ID,\n",
        "    load_in_4bit = True,\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        ")"
      ],
      "metadata": {
        "id": "vtNJ3an0bDux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pred_rows = []\n",
        "\n",
        "for idx, sample in tqdm.tqdm(enumerate(test), total=len(test)):\n",
        "    pil_img = next(c for c in sample[\"messages\"][0][\"content\"]\n",
        "                   if c[\"type\"]==\"image\")[\"image\"]\n",
        "    if isinstance(pil_img, dict):\n",
        "        pil_img = Image.open(pil_img[\"path\"])\n",
        "    elif isinstance(pil_img, str):\n",
        "        pil_img = Image.open(pil_img)\n",
        "    if pil_img.mode == \"L\":\n",
        "        pil_img = pil_img.convert(\"RGB\")\n",
        "\n",
        "    instruction = \"Which insect bite is this if there is a bite? Return only bite name or no bite, no additional comment needed\"\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": pil_img},\n",
        "                {\"type\": \"text\", \"text\": instruction}\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    inputs = processor.apply_chat_template(\n",
        "      messages,\n",
        "      add_generation_prompt=True,\n",
        "      tokenize=True,\n",
        "      return_dict=True,\n",
        "      return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = raw_model.generate(**inputs, max_new_tokens=512)\n",
        "    print(raw_processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))\n",
        "    prompt_len = inputs[\"input_ids\"].shape[-1]\n",
        "    answer_ids = outputs[0, prompt_len:]  # remove prompt tokens\n",
        "    answer_text = raw_processor.tokenizer.decode(\n",
        "              answer_ids, skip_special_tokens=True\n",
        "    ).strip()\n",
        "\n",
        "    print(\"Prediction: \" + answer_text + \".   Real Answer: \" + sample[\"messages\"][1][\"content\"][0][\"text\"])\n",
        "    raw_pred_rows.append({\n",
        "        \"row_idx\":        idx,\n",
        "        \"gold_label\":     sample[\"messages\"][1][\"content\"][0][\"text\"],\n",
        "        \"raw_prediction\": answer_text,\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(raw_pred_rows)\n",
        "df.to_csv(\"predictions_raw_model.csv\", index=False)\n",
        "print(f\"✅  Saved {len(df)} rows to predictions.csv\")"
      ],
      "metadata": {
        "id": "sjxMiuE6bd55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q -U \"google-genai>=0.6.0\" tqdm"
      ],
      "metadata": {
        "id": "uG4NIqvXYb1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "CNRkJmGiYu_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_key = userdata.get('GEMINI_KEY')\n",
        "MODEL_NAME = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "bcKbrdcCYi8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=gemini_key)\n",
        "gemini_model = genai.GenerativeModel(MODEL_NAME)"
      ],
      "metadata": {
        "id": "X-uOtTu_Yzdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, time, pandas as pd\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "CSV_PATH = \"/content/predictions_raw_model.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "required_cols = {\"gold_label\", \"raw_prediction\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "assert not missing, f\"❌ Missing columns in CSV: {missing}\"\n",
        "\n",
        "client = genai.Client(api_key=gemini_key)\n",
        "\n",
        "\n",
        "def generate_promt(gt, pred):\n",
        "    return f\"\"\"\n",
        "      You are a grading assistant.\n",
        "\n",
        "      INPUT (given at runtime)\n",
        "      {{\n",
        "        \"prediction\": \"<model output>\",\n",
        "        \"answer\":     \"<ground-truth label>\"\n",
        "      }}\n",
        "\n",
        "      TASK\n",
        "      1. **Normalise** both strings:\n",
        "        • lower-case\n",
        "        • trim leading/trailing spaces\n",
        "        • replace every non-alphabetic character (underscores, punctuation, etc.) with a single space\n",
        "        • collapse multiple spaces into one\n",
        "\n",
        "      2. **Tokenise** (split on spaces).\n",
        "\n",
        "      3. **Singularise** each token with this simple rule:\n",
        "        – if the token ends with “s” **and** its length > 3, drop the trailing “s”.\n",
        "        (thus “bites” → “bite”, “fleas” → “flea”, but “wasps” → “wasp”).\n",
        "\n",
        "      4. Let **P** be the set of tokens from *prediction*, **A** the set from *answer*.\n",
        "        If **A ⊆ P** **or** **P ⊆ A**, the result is **pass**; otherwise **fail**.\n",
        "\n",
        "      OUTPUT – exactly and only this JSON schema:\n",
        "\n",
        "      {{\n",
        "        \"pass\": true\n",
        "      }}\n",
        "\n",
        "     **Answer:**\\n{gt}\\n\\n**Prediction:**\\n{pred}\\n\n",
        "     \"\"\"\n",
        "\n",
        "def grade_row(gt: str, pred: str, tries: int = 3):\n",
        "\n",
        "    prompt = generate_promt(gt, pred)\n",
        "\n",
        "    for attempt in range(1, tries + 1):\n",
        "        try:\n",
        "          response = client.models.generate_content(\n",
        "          model=\"gemini-2.5-flash\",\n",
        "          contents=prompt,\n",
        "          config=types.GenerateContentConfig(\n",
        "              response_mime_type=\"application/json\",\n",
        "            ),\n",
        "          )\n",
        "          print(response.text)\n",
        "          data = json.loads(response.text)\n",
        "          print(data)\n",
        "          print(f\"\\nGold: {gt}\\nPred: {pred}\\n→ {data}\")\n",
        "          return data[\"pass\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt}/{tries} failed: {e}\")\n",
        "            if attempt == tries:\n",
        "                return None, f\"✖️ {e}\"\n",
        "            time.sleep(2 * attempt)"
      ],
      "metadata": {
        "id": "k4-r8h42lZMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, gold_label, prediction = [], [],[]\n",
        "for _, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        print(row)\n",
        "        sc = grade_row(gt=row[\"gold_label\"], pred=row[\"raw_prediction\"])\n",
        "        scores.append(sc)\n",
        "        gold_label.append(row[\"gold_label\"])\n",
        "        prediction.append(row[\"raw_prediction\"])\n",
        "\n",
        "    except Exception as e:\n",
        "        raise e\n",
        "\n",
        "\n",
        "df[\"result\"] = scores\n",
        "df[\"gold_label\"] = gold_label\n",
        "df[\"prediction\"] = prediction"
      ],
      "metadata": {
        "id": "vnIOsqO7ljVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"pred_vs_real_with_result_raw.csv\", index=False)"
      ],
      "metadata": {
        "id": "qErsFWcO5abQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"result\"]"
      ],
      "metadata": {
        "id": "YxQMcgvOFOO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (df[\"result\"] == True).mean() * 100\n",
        "\n",
        "result_counts = df[\"result\"].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar([\"Accuracy\"], [accuracy], color=\"skyblue\")\n",
        "plt.ylim(0, 100)\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "result_counts = df['result'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(result_counts.index.astype(str), result_counts.values, color=[\"red\", \"green\"])\n",
        "plt.xlabel(\"Result\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"True vs False Predictions\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PIFZEcWQE2ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Raw model accuracy \" + str(accuracy) + \"%\")"
      ],
      "metadata": {
        "id": "TWlphCR-FDXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_results = df.groupby(['gold_label', 'result']).size().unstack(fill_value=0)\n",
        "\n",
        "# Plot side-by-side bars for True and False per class\n",
        "class_results.plot(kind='bar', figsize=(10,5))\n",
        "plt.xlabel(\"Gold Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"True vs False Predictions per Class\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title=\"Result\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YT56uIiwGap2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw = pd.read_csv(\"pred_vs_real_with_result_raw.csv\")\n",
        "df_ft = pd.read_csv(\"pred_vs_real_with_result.csv\")"
      ],
      "metadata": {
        "id": "ZmQ0gmDLHIyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticks_df = df_raw[df_raw['gold_label'] == 'ticks']\n",
        "ticks_accuracy = (ticks_df['result'] == True).mean() * 100\n",
        "\n",
        "ticks_df_ft = df_ft[df_ft['gold_label'] == 'ticks']\n",
        "ticks_accuracy_ft = (ticks_df_ft['result'] == \"pass\").mean() * 100"
      ],
      "metadata": {
        "id": "Bivhv8KLHPRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_data = pd.DataFrame({\n",
        "    \"Model\": [\"Raw\", \"FT\"],\n",
        "    \"Accuracy (%)\": [ticks_accuracy, ticks_accuracy_ft]\n",
        "})\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.bar(accuracy_data[\"Model\"], accuracy_data[\"Accuracy (%)\"])\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Ticks Accuracy Comparison\")\n",
        "for idx, val in enumerate(accuracy_data[\"Accuracy (%)\"]):\n",
        "    plt.text(idx, val + 1, f\"{val:.2f}%\", ha='center')\n",
        "plt.ylim(0, 100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W9SkkUbLHuHY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}